{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4w6BnnfkL7Ic"
   },
   "source": [
    "# Using Python to Reverse-Engineer Guitar Effects\n",
    "Author: Dan Lynch\\\n",
    "Date: November 21, 2020\n",
    "\n",
    "---\n",
    "\n",
    "This notebook will demonstrate some concepts in signal processing and some signal processing/analysis tools available in Python, primarily SciPy.\n",
    "\n",
    "We'll use a \"simple\" example: distortion, in the style of the infamous Boss MT-2 Metal Zone pedal.\n",
    "Although nonlinear, distortion is a little easier to demonstrate than delay-based effects such as echo, reverb, chorus, flanger, and phaser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of Python modules for working with audio files; see [here](https://www.audiolabs-erlangen.de/resources/MIR/FMP/B/B_PythonAudio.html) for a helpful list. You'll see SciPy in that list, but the authors note that it doesn't always work well, and I have found that too. Instead, I'm using a module named [SoundFile](https://pysoundfile.readthedocs.io/en/0.9.0/#) that has a clean API. First we need to install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9IDTmOrMMep"
   },
   "source": [
    "## Load Audio Files\n",
    "This tutorial starts with two WAV files:\n",
    "* `riff_clean.wav`: an unprocessed signal, recorded from my guitar direct to my computer\n",
    "* `riff_dist.wav`: a heavily-distorted signal, recorded from my guitar passed through a Digitech RP-70 modeling pedal. This pedal is an all-in-one device that emulates a rack-full of guitar effects, including various amplifiers, compressors, EQs, chorus/flanger/phaser, and echo/reverb.\n",
    "\n",
    "Here's the signal chain:\n",
    "<img src=\"https://raw.githubusercontent.com/dlynch7/reverse_engineer_guitar_fx/main/distortion/recording_sig_chain.png\" alt=\"recording_signal_chain\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "id": "auxEB2d2L2Wd",
    "outputId": "7dad6b8d-4236-4ae7-be39-cd80250c3b42"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# get the clean riff WAV:\n",
    "riff_clean_url = 'https://raw.githubusercontent.com/dlynch7/reverse_engineer_guitar_fx/main/distortion/riff_clean.wav'\n",
    "\n",
    "Audio(url=riff_clean_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "id": "jsEE0V7QcBbY",
    "outputId": "44cf28d7-21f0-41d9-a395-6bae71cb1767"
   },
   "outputs": [],
   "source": [
    "# get the distorted riff WAV:\n",
    "riff_dist_url = 'https://raw.githubusercontent.com/dlynch7/reverse_engineer_guitar_fx/main/distortion/riff_dist.wav'\n",
    "\n",
    "Audio(url=riff_dist_url) # it's a lot louder than the clean recording, so don't destroy your ears!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMhshUDlhz_4"
   },
   "source": [
    "We're going to be doing a lot with these audio clips, so let's download them, temporarily, to our local workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oTPst8BhzWi",
    "outputId": "d51d5eb6-7cb7-4c65-8a5b-d295c5b01a8d"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(riff_clean_url, allow_redirects=True)\n",
    "open('riff_clean.wav', 'wb').write(r.content) # 'wb' because we are writing a *binary* file\n",
    "\n",
    "r = requests.get(riff_dist_url, allow_redirects=True)\n",
    "open('riff_dist.wav', 'wb').write(r.content) # 'wb' because we are writing a *binary* file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhmtwVrFixO2"
   },
   "source": [
    "Open your Colab notebook's filesystem by clicking on the folder icon to the left. You should see these files now. To see their sizes, mouse over them: both should be around 2 MB.\n",
    "\n",
    "These files are \"large\" because they are WAV files, and WAV is one of the _**uncompressed**_ audio formats. In contrast, MP3s are smaller because they are compressed audio formats. Compression removes some audio information, and we want all the information available as we proceed to analyze and modify these signals, so that's why we're using WAV instead of MP3.\n",
    "\n",
    "One more thing about the format: I recorded to 16-bit WAV files; 16-bit is typical CD-quality audio. You can record to 24-bit and 32-bit too (audio professionals use these resolutions), but those files are bigger, and it's hard to hear the difference. 16-bit is good enough for our purposes. The important thing is that the audio data is uncompressed.\n",
    "\n",
    "Google Colab wasn't designed with audio processing in mind, and I'm unable to autosave my notebook once I download those two audio files. To get around this, execute the following cells in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBmmDE1bTS6a",
    "outputId": "9e62441f-88e9-45d1-f43b-1aab32f8fa10"
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import scipy.io\n",
    "import soundfile as sf\n",
    "\n",
    "riff_clean_data, riff_clean_samplerate = sf.read('riff_clean.wav')\n",
    "riff_clean_dict = {'wav_data':riff_clean_data,\n",
    "                   'samplerate':riff_clean_samplerate,\n",
    "                   'wav_fname':'riff_clean.wav'}\n",
    "print(riff_clean_dict)\n",
    "\n",
    "riff_dist_data, riff_dist_samplerate = sf.read('riff_dist.wav')\n",
    "riff_dist_dict = {'wav_data':riff_dist_data,\n",
    "                  'samplerate':riff_dist_samplerate,\n",
    "                  'wav_fname':'riff_dist.wav'}\n",
    "print(riff_dist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEC_XcvRSzbq"
   },
   "outputs": [],
   "source": [
    "# !rm riff_clean.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5H4Bad9S5wY"
   },
   "outputs": [],
   "source": [
    "# !rm riff_dist.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-BCbSzajZav"
   },
   "source": [
    "## Visualize each waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zi8c-kX3isqF",
    "outputId": "3045847b-1b63-4766-e3aa-f1553bf2df1c"
   },
   "outputs": [],
   "source": [
    "# code based on \n",
    "# 1) https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.read.html\n",
    "# 2) https://matplotlib.org/3.3.3/gallery/lines_bars_and_markers/cohere.html#sphx-glr-gallery-lines-bars-and-markers-cohere-py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 16.0\n",
    "\n",
    "def plot_wave(wav_dict):\n",
    "  wav_data = wav_dict['wav_data']\n",
    "  samplerate = wav_dict['samplerate']\n",
    "\n",
    "  # print(f\"number of channels = {wav_data.shape[1]}\")\n",
    "  length = wav_data.shape[0] / samplerate\n",
    "  # print(f\"length = {length}s\")\n",
    "  time = np.linspace(0., length, wav_data.shape[0])\n",
    "  \n",
    "  fig, axs = plt.subplots(wav_data.shape[1],1,figsize=(20, 10))\n",
    "  for channel in range(wav_data.shape[1]):\n",
    "    axs[channel].plot(time, wav_data[:, channel])\n",
    "    axs[channel].set_ylabel(\"Channel %d Amplitude\" % channel)\n",
    "    axs[channel].grid(True)\n",
    "  axs[-1].set_xlabel(\"Time [s]\")\n",
    "  axs[0].set_title(wav_dict['wav_fname'])\n",
    "  plt.show()\n",
    "  return\n",
    "\n",
    "plot_wave(riff_clean_dict)\n",
    "plot_wave(riff_dist_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAZQVhbaolS9"
   },
   "source": [
    "Interesting! We can make an interesting observation already:\n",
    "\n",
    "Notice that the distorted riff has near-constant amplitude, while the clean riff only has loud transients corresponding to each note I picked on the guitar.\n",
    "So why the difference in perceived loudness? It's in our heads (a psychoacoustic effect): our ears/brains don't perceive instantaneous loudness but rather average loudness over some time window.\n",
    "This explains why the distorted riff sounds much louder than the clean riff, even though they have almost identical peak amplitudes.\n",
    "\n",
    "As an aside, this psychoacoustic effect led to widespread use (some might say abuse) of an audio effect called \"limiting\" which makes quiet parts louder. This effect was a key player in the \"[Loudness War](https://en.wikipedia.org/wiki/Loudness_war)\" of the 2000s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1FhDtV4rcMI"
   },
   "source": [
    "## How does distortion work?\n",
    "Let's zoom in near the end of the riff and compare the clean and distorted signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uhFnz-u3roto",
    "outputId": "f071cf86-96cc-405c-ad11-ea6effc0c4c0"
   },
   "outputs": [],
   "source": [
    "def overlay_wavs(wav_dict_list,t_start,t_end):\n",
    "  if not type(wav_dict_list) is list:\n",
    "    raise TypeError('type(wav_dict_list) must be list.')\n",
    "  if wav_dict_list == []:\n",
    "    raise ValueError('wav_dict_list must have at least one element.')\n",
    "  if not type(wav_dict_list[0]) is dict:\n",
    "    raise TypeError('elements of wav_dict_list must be of type dict.') # could be more robust than it is\n",
    "  if not (type(t_start) is float or type(t_start) is int):\n",
    "    raise TypeError('type(t_start) must be float or int.')\n",
    "  if not (type(t_end) is float or type(t_end) is int):\n",
    "    raise TypeError('type(t_end) must be float or int.')\n",
    "\n",
    "  if not t_start > 0:\n",
    "    raise ValueError('t_start must be > 0')\n",
    "  if not t_end > t_start:\n",
    "    raise ValueError('t_start must be < t_end')\n",
    "\n",
    "  # create a local dictionary to contain additional info:\n",
    "  wavs_data = []\n",
    "  for i in range(len(wav_dict_list)):\n",
    "    length = wav_dict_list[i]['wav_data'].shape[0] / wav_dict_list[i]['samplerate']\n",
    "    if not t_end < length:\n",
    "      raise ValueError('t_end must be < %f' % length)\n",
    "    time = np.linspace(0., length, wav_dict_list[i]['wav_data'].shape[0])\n",
    "    wavs_data.append({'fname':      wav_dict_list[i]['wav_fname'],\n",
    "                      'samplerate': wav_dict_list[i]['samplerate'],\n",
    "                      'data':       wav_dict_list[i]['wav_data'],\n",
    "                      'length':     length,\n",
    "                      'time':       time})\n",
    "\n",
    "  fig, axs = plt.subplots(len(wav_dict_list),1,figsize=(20, 10))\n",
    "  for i in range(len(wavs_data)):\n",
    "    n_start = int(t_start*wavs_data[i]['samplerate'])\n",
    "    n_end = int(t_end*wavs_data[i]['samplerate'])\n",
    "    t_range = np.linspace(t_start, t_end, n_end - n_start)\n",
    "    axs[i].plot(t_range, wavs_data[i]['data'][n_start:n_end, 0]) # looking at channel 0, i.e., the left channel\n",
    "    axs[i].set_ylabel(\"Channel 0 Amplitude, %s\" % wavs_data[i]['fname'])\n",
    "    axs[i].grid(True)\n",
    "  axs[-1].set_xlabel(\"Time [s]\")\n",
    "  axs[0].set_title('Comparison of signals for %f <= time <= %f' % (t_start,t_end))\n",
    "  plt.show()\n",
    "  return\n",
    "\n",
    "overlay_wavs([riff_clean_dict,riff_dist_dict],10.85,12.3)\n",
    "overlay_wavs([riff_clean_dict,riff_dist_dict],10.85,11.0)\n",
    "overlay_wavs([riff_clean_dict,riff_dist_dict],10.85,10.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc9NoA5d5B5e"
   },
   "source": [
    "Bear in mind that the upper signal is clean and the lower signal is distorted.\n",
    "Let's take stock of what we can see after three rounds of zooming in on the signal:\n",
    "* the distorted signal is louder;\n",
    "* the distorted signal has more high-frequency content than the clean signal. You can see this pretty clearly around 10.86 seconds;\n",
    "* the amplitude of the clean signal appears to exponentially decay after each transient, and if you imagine a vibrating string (and, indeed, the partial differential equation that models a vibrating string - the \"wave equation\"), this makes physical sense;\n",
    "* the decay envelope of the distorted signal is \"concave down\", whereas the decay envelope of the clean signal is \"concave up\". This is noticeable at 10.85s, 10.865s, 10.88s, etc. This doesn't make physical sense!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKG58Ihl65fE"
   },
   "source": [
    "### Overdrive and clipping\n",
    "What's going on with the distorted signal might make more sense when you think about how guitar distortion works: _**clipping**_.\n",
    "\n",
    "Most distortion effects are based on two stages:\n",
    "* a gain stage (often achieved with a vacuum tube, a transistor, or an op-amp) that amplifies an incoming signal _a lot_.\n",
    "* a clipping stage (sometimes built into the gain stage, other times achieved separately with a pair of diodes) that doesn't let the amplitude exceed some threshold.\n",
    "\n",
    "Together, they act on an incoming signal thusly:\n",
    "![proco_rat_clipping](https://www.electrosmash.com/images/tech/pro-co-rat/pro-co-rat-clipped-waveform.png)\n",
    "\n",
    "The graph above comes from a [teardown and analysis of the ProCo RAT pedal](https://www.electrosmash.com/proco-rat) that does a great job explaining how this effect can be achieved using discrete electronic components.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxMdPHvF86jD"
   },
   "source": [
    "### What does clipping *sound* like?\n",
    "We just saw what clipping *looks* like, when applied to a pure sine wave, but what does it sound like? To answer that, let's mock up a clipping stage in Python, and let's implement it as a function that acts on NumPy arrays, since we can convert WAV files to NumPy arrays.\n",
    "\n",
    "### Software clipping, attempt 1: hard (square) clipping\n",
    "This function will need to take at least two inputs:\n",
    "* an incoming signal, `sig_in`, which will be a NumPy array\n",
    "* a threshold amplitude, `clip_thresh`, above which clipping will happen. Let's use a float between 0 and 1.\n",
    "\n",
    "We'll rescale the clipping threshold to 15-bit range (0 to 2^15 - 1) inside the function. We're working with 16-bit audio, and audio is an AC signal, with positive and negative amplitude, so the maximum amplitude is 2^15 - 1 and the minimum amplitude is -2^15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "PCmXX_SE_qNL",
    "outputId": "1d763f01-e0b5-41c7-cef4-b64bf5a09a0d"
   },
   "outputs": [],
   "source": [
    "def hard_clipper(sig_in,clip_thresh):\n",
    "  if not type(sig_in) is np.ndarray:\n",
    "    raise TypeError('type(sig_in) must be numpy.ndarray')\n",
    "  if not (type(clip_thresh) is float or type(clip_thresh) is int):\n",
    "    raise TypeError('type(clip_thresh) must be float or int')\n",
    "  if (clip_thresh > 1 or clip_thresh < 0):\n",
    "    raise ValueError('clip_thresh must be between 0 and 1.')\n",
    "\n",
    "  sig_out = sig_in.copy()\n",
    "  pos_thresh = clip_thresh\n",
    "  neg_thresh = -clip_thresh\n",
    "\n",
    "  # clip the positive part of sig_in:\n",
    "  pos_clip_indices = sig_in > pos_thresh\n",
    "  sig_out[pos_clip_indices] = pos_thresh\n",
    "\n",
    "  # clip the negative part of sig_in:\n",
    "  neg_clip_indices = sig_in < neg_thresh\n",
    "  sig_out[neg_clip_indices] = neg_thresh\n",
    "\n",
    "  return sig_out\n",
    "\n",
    "samplerate = 44100; fs = 5 # too low to hear, but easy to see\n",
    "t = np.linspace(0., 1., samplerate)\n",
    "amplitude = 1\n",
    "sine_data = amplitude * np.sin(2. * np.pi * fs * t)\n",
    "\n",
    "hard_clip_75 = hard_clipper(sine_data,0.75)\n",
    "hard_clip_50 = hard_clipper(sine_data,0.50)\n",
    "hard_clip_25 = hard_clipper(sine_data,0.25)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(20, 10))\n",
    "ax.plot(t, sine_data,label='thresh = 1.0')\n",
    "ax.plot(t, hard_clip_75,label='thresh = 0.75')\n",
    "ax.plot(t, hard_clip_50,label='thresh = 0.50')\n",
    "ax.plot(t, hard_clip_25,label='thresh = 0.25')\n",
    "\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7ObnpU2NvP1"
   },
   "source": [
    "### Making up lost amplitude\n",
    "Clipping is an effective way to introduce distortion, but it also makes everything quieter, and that isn't very fun. To fix that, most distortion effects have another gain stage after the clipping stage.\n",
    "\n",
    "In Python, it's even easier: if we know our clipping threshold, we also know the amount of make-up gain we need to apply:\n",
    "```python\n",
    "makeup_gain = 1/clip_thresh\n",
    "```\n",
    "* if `clip_thresh` = 1, `makeup_gain` = 1\n",
    "* if `clip_thresh` = 0.5, `makeup_gaint` = 2\n",
    "* if `clip_thresh` = 0.1, `makeup_gain` = 10\n",
    "\n",
    "Let's include this makeup gain in our hard-clipping function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "g1EDMfzdPjO8",
    "outputId": "7a85c200-3a0a-4c3f-867e-c757d84b4d08"
   },
   "outputs": [],
   "source": [
    "def hard_clipper_makeup(sig_in,clip_thresh):\n",
    "  if not type(sig_in) is np.ndarray:\n",
    "    raise TypeError('type(sig_in) must be numpy.ndarray')\n",
    "  if not (type(clip_thresh) is float or type(clip_thresh) is int):\n",
    "    raise TypeError('type(clip_thresh) must be float or int')\n",
    "  if (clip_thresh > 1 or clip_thresh < 0):\n",
    "    raise ValueError('clip_thresh must be between 0 and 1.')\n",
    "\n",
    "  sig_out = sig_in.copy()\n",
    "\n",
    "  # clip the positive part of sig_in:\n",
    "  pos_clip_indices = sig_in > clip_thresh\n",
    "  sig_out[pos_clip_indices] = clip_thresh\n",
    "\n",
    "  # clip the negative part of sig_in:\n",
    "  neg_clip_indices = sig_in < -clip_thresh\n",
    "  sig_out[neg_clip_indices] = -clip_thresh\n",
    "\n",
    "  # make up attenuation due to clipping. This is a little more robust than\n",
    "  # the method described in the text above, but functionally equivalent:\n",
    "  sig_out = (sig_out / np.max(np.abs(sig_out))) # a little less than 32768.\n",
    "\n",
    "  return sig_out\n",
    "\n",
    "samplerate = 44100; fs = 100\n",
    "t = np.linspace(0., 1, samplerate)\n",
    "amplitude = 1\n",
    "sine_data = amplitude * np.sin(2. * np.pi * fs * t)\n",
    "\n",
    "hard_clip_mu_75 = hard_clipper_makeup(sine_data,0.75)\n",
    "hard_clip_mu_50 = hard_clipper_makeup(sine_data,0.50)\n",
    "hard_clip_mu_25 = hard_clipper_makeup(sine_data,0.25)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(20, 10))\n",
    "T = 1000\n",
    "ax.plot(t[0:T], sine_data[0:T],label='thresh = 1.0')\n",
    "ax.plot(t[0:T], hard_clip_mu_75[0:T],label='thresh = 0.75')\n",
    "ax.plot(t[0:T], hard_clip_mu_50[0:T],label='thresh = 0.50')\n",
    "ax.plot(t[0:T], hard_clip_mu_25[0:T],label='thresh = 0.25')\n",
    "\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVzRKWA2qZSG"
   },
   "source": [
    "### Visualizing hard-clipping in the frequency domain\n",
    "Although clipping alone is not soley responsible for the original distorted guitar sound, it does explain one thing we saw earlier: the high frequency content in the distorted guitar recording.\n",
    "\n",
    "Let's explore that a little more closely, using a signal analysis tool called the [Fast Fourier Transform](https://en.wikipedia.org/wiki/Fast_Fourier_transform) (FFT). This is a numerical algorithm for finding the frequency content of a signal, and it is based on the idea that an arbitrary periodic signal can be approximated by an infinite sum of sines and cosines.\n",
    "\n",
    "First we'll use SciPy to take the FFT of our sine wave and the various hard-clipped versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q_AJ-jhTaXP3",
    "outputId": "e32dbaec-ef05-4225-a64f-cb74feeb7a8b"
   },
   "outputs": [],
   "source": [
    "# based on https://realpython.com/python-scipy-fft/\n",
    "\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "\n",
    "# Number of samples:\n",
    "N = int(samplerate * t[-1]) # cast to int b/c required by rfftfreq.\n",
    "\n",
    "fmax = int(1e3)\n",
    "xf = [[],[],[],[]]\n",
    "yf = [[],[],[],[]]\n",
    "\n",
    "# take the FFT of the unclipped sine wave:\n",
    "yf[0] = rfft(sine_data)\n",
    "xf[0] = rfftfreq(N, 1/samplerate)\n",
    "\n",
    "# FFT of lightly-clipped sine wave:\n",
    "yf[1] = rfft(hard_clip_mu_75)\n",
    "xf[1] = rfftfreq(N, 1/samplerate)\n",
    "\n",
    "# FFT of moderately-clipped sine wave:\n",
    "yf[2] = rfft(hard_clip_mu_50)\n",
    "xf[2] = rfftfreq(N, 1/samplerate)\n",
    "\n",
    "# FFT of heavily-clipped sine wave:\n",
    "yf[3] = rfft(hard_clip_mu_25)\n",
    "xf[3] = rfftfreq(N, 1/samplerate)\n",
    "\n",
    "fig, axs = plt.subplots(2,2,figsize=(20,20))\n",
    "axs[0,0].plot(xf[0][0:fmax], np.abs(yf[0][0:fmax])*(2/N))\n",
    "axs[0,0].set_xlabel('Frequency [Hz]')\n",
    "axs[0,0].set_ylabel('Amplitude')\n",
    "axs[0,0].set_title('FFT, unclipped signal')\n",
    "\n",
    "axs[0,1].plot(xf[1][0:fmax], np.abs(yf[1][0:fmax])*(2/N))\n",
    "axs[0,1].set_xlabel('Frequency [Hz]')\n",
    "axs[0,1].set_ylabel('Amplitude')\n",
    "axs[0,1].set_title('FFT, lightly-clipped signal')\n",
    "\n",
    "axs[1,0].plot(xf[2][0:fmax], np.abs(yf[2][0:fmax])*(2/N))\n",
    "axs[1,0].set_xlabel('Frequency [Hz]')\n",
    "axs[1,0].set_ylabel('Amplitude')\n",
    "axs[1,0].set_title('FFT, moderately-clipped signal')\n",
    "\n",
    "axs[1,1].plot(xf[3][0:fmax], np.abs(yf[3][0:fmax])*(2/N))\n",
    "axs[1,1].set_xlabel('Frequency [Hz]')\n",
    "axs[1,1].set_ylabel('Amplitude')\n",
    "axs[1,1].set_title('FFT, heavily-clipped signal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eB5ioQ4vefJm"
   },
   "source": [
    "Let's try our hard-clipper (with gain makeup) on `riff_clean.wav` and see how it sounds. Don't get your hopes up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "riff_hc75_data = hard_clipper_makeup(riff_clean_dict['wav_data'],0.75) # sounds almost like the clean signal\n",
    "sf.write('riff_hc75.wav',riff_hc75_data,44100)\n",
    "riff_hc75_dict = {'wav_data':riff_hc75_data,\n",
    "                  'samplerate':44100,\n",
    "                  'wav_fname':'riff_hc75.wav'}\n",
    "plot_wave(riff_hc75_dict)\n",
    "\n",
    "riff_hc50_data = hard_clipper_makeup(riff_clean_dict['wav_data'],0.50) # crunch is barely perceptible\n",
    "sf.write('riff_hc50.wav',riff_hc50_data,44100)\n",
    "riff_hc50_dict = {'wav_data':riff_hc50_data,\n",
    "                  'samplerate':44100,\n",
    "                  'wav_fname':'riff_hc50.wav'}\n",
    "plot_wave(riff_hc50_dict)\n",
    "\n",
    "riff_hc25_data = hard_clipper_makeup(riff_clean_dict['wav_data'],0.25) # crunch begins to be noticeable, still pretty clean\n",
    "sf.write('riff_hc25.wav',riff_hc25_data,44100)\n",
    "riff_hc25_dict = {'wav_data':riff_hc25_data,\n",
    "                  'samplerate':44100,\n",
    "                  'wav_fname':'riff_hc25.wav'}\n",
    "plot_wave(riff_hc25_dict)\n",
    "\n",
    "riff_hc10_data = hard_clipper_makeup(riff_clean_dict['wav_data'],0.10) # now it's starting to really distort\n",
    "sf.write('riff_hc10.wav',riff_hc10_data,44100)\n",
    "riff_hc10_dict = {'wav_data':riff_hc10_data,\n",
    "                  'samplerate':44100,\n",
    "                  'wav_fname':'riff_hc10.wav'}\n",
    "plot_wave(riff_hc10_dict)\n",
    "\n",
    "riff_hc05_data = hard_clipper_makeup(riff_clean_dict['wav_data'],0.05) # now it's starting to really distort\n",
    "sf.write('riff_hc05.wav',riff_hc05_data,44100)\n",
    "riff_hc05_dict = {'wav_data':riff_hc05_data,\n",
    "                  'samplerate':44100,\n",
    "                  'wav_fname':'riff_hc05.wav'}\n",
    "plot_wave(riff_hc05_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_hc75.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_hc50.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_hc25.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_hc10.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_hc05.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandpass filtering, before clipping stage\n",
    "We're making good progress toward reverse-engineering the original distorted guitar sound. For comparison, here it is again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_dist.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh. Hm. We're not so close after all. If it's any comfort, I faced this same exact problem when I was building a hardware distortion pedal based on the ProCo RAT circuit: it distorted just fine, but it sounded \"fuzzy\" and not, well, metal.\n",
    "\n",
    "Here's the current problem:\n",
    "* in the absence of any filtering before the clipping stage, the low-frequency signal content from my guitar dominates the clipping stage and makes the clipper's output sound \"fuzzy\", like a blown speaker.\n",
    "* I can't keep adding more distortion (cranking up the gain on the input to the clipper, or equivalently, reducing the clipping threshold and then adding makeup gain).\n",
    "* in other words, I want more distortion, but not at the low frequencies\n",
    "\n",
    "How did I achieve that? Filtering! Specifically, bandpass filtering. Here's why that helps:\n",
    "* First, I filter out low-frequency content before the clipping stage\n",
    "* Then, I really crank up the distortion at the clipping stage, by reducing the clipping threshold\n",
    "* As a result, the mid-range frequencies distort while the bottom-end is attenuated\n",
    "\n",
    "I didn't exactly come up with this myself. The Boss Metal Zone pedal [does this exact same thing](https://electricdruid.net/boss-mt-2-metal-zone-pedal-analysis/), albeit much more cleverly.\n",
    "\n",
    "### Complementary Filters\n",
    "So, now we come to a question: how does one implement a filter in Python? This is potentially a bottomless rabbit hole, but before diving in, let's look at a really simple approach to digital filters: the _**complementary filter**_. This is basically a weighted average.\n",
    "\n",
    "Consider an input signal $x$ and an output signal $y$. These are discrete-time signals, so they can be written as $x[i], y[i],\\  i = 1,2,\\ldots,n$. It often makes sense to think of $x[n]$ and $y[n]$ as the \"current\" input and output, $x[n-1]$ and $y[n-1]$ as the \"previous\" input and output, and so on.\n",
    "\n",
    "The next two equations use scalar gains $a$ and $b$ which are required to be between 0 and 1.\n",
    "\n",
    "There are two basic kinds of complementary filters. They are recursive, because they process an input signal as well as their past outputs. These filters belong to a larger family of filters called \"infinite-impulse-response\" (IIR) filters. As you might guess, there is a separate family of \"finite-impulse-response\" (FIR) filters. Each filter architecture has pros and cons.\n",
    "\n",
    "The next two examples demonstrate two complementary filter equations.\n",
    "\n",
    "#### Complementary lowpass filter\n",
    "The block diagram of a complementary lowpass filter is\n",
    "<img src=\"https://raw.githubusercontent.com/dlynch7/reverse_engineer_guitar_fx/main/distortion/LPF.png\" alt=\"LPF.png\" width=\"600\"/>\n",
    "If you haven't seen these kinds of block diagrams before, don't worry. They're pretty straightforward. The one symbol you might find unfamiliar is the triangle with numbers/letters inside it: that represents a \"gain\" stage, where the output signal's amplitude is some multiple or fraction of the input signal's amplitude, depending on the value of the number/letter inside the triangle.\n",
    "\n",
    "The equation for a complementary highpass filter is\n",
    "\\begin{equation}\n",
    "y[n]=(1-a)x[n] + a y[n-1]\n",
    "\\end{equation}\n",
    "\n",
    "Think of this as a weighted average between the current input and the previous output. Consider two limits:\n",
    "* As $a\\rightarrow 0$, $y[n] \\rightarrow x[n]$, in which case the output is simply the input, and no filtering occurs; all input signal content is passed through.\n",
    "* As $a\\rightarrow 1$, $y[n] \\rightarrow y[n-1]$, in which case the output doesn't change in response to input; the signal is maximally lowpass filtered because only the DC component remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowpass_iir(sig_in,filt_coef):\n",
    "    if not type(sig_in) is np.ndarray:\n",
    "      raise TypeError('type(sig_in) must be numpy.ndarray')\n",
    "    if not (type(filt_coef) is float or type(filt_coef) is int):\n",
    "      raise TypeError('type(filt_coef) must be float or int')\n",
    "    if (filt_coef > 1 or filt_coef < 0):\n",
    "      raise ValueError('filt_coef must be between 0 and 1.')\n",
    "    \n",
    "    sig_out = np.zeros_like(sig_in)\n",
    "#     print(sig_out.shape)\n",
    "    \n",
    "    for n in range(1,sig_in.shape[0]): # notice that we're starting at \"1\" instead of \"0\"\n",
    "        sig_out[n] = (1-filt_coef)*sig_in[n] + filt_coef*sig_out[n-1]\n",
    "    \n",
    "    return sig_out\n",
    "\n",
    "# To test our lowpass filter, create a sinusoidal signal and then hard-clip it:\n",
    "samplerate = 44100; fs = 100\n",
    "t = np.linspace(0., 1, samplerate)\n",
    "amplitude = 1\n",
    "sine_data = amplitude * np.sin(2. * np.pi * fs * t)\n",
    "hard_clip_mu_10 = hard_clipper_makeup(sine_data,0.10) # this will look like a square wave: lots of harmonic content!\n",
    "\n",
    "# Now let's lowpass-filter our quasi-square wave:\n",
    "lpf_square_wave_50 = lowpass_iir(hard_clip_mu_10,0.5) # set the filter coefficient to 0.5\n",
    "lpf_square_wave_75 = lowpass_iir(hard_clip_mu_10,0.75) # set the filter coefficient to 0.75\n",
    "lpf_square_wave_90 = lowpass_iir(hard_clip_mu_10,0.90) # set the filter coefficient to 0.90\n",
    "lpf_square_wave_95 = lowpass_iir(hard_clip_mu_10,0.95) # set the filter coefficient to 0.90\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(20, 10))\n",
    "T = 1000\n",
    "ax.plot(t[0:T], sine_data[0:T],label='pure sine')\n",
    "ax.plot(t[0:T], hard_clip_mu_10[0:T],label='in: hard-clipped sine, thresh = 0.10')\n",
    "ax.plot(t[0:T], lpf_square_wave_50[0:T],label=\"out: LPF'd sine, coeff = 0.5\")\n",
    "ax.plot(t[0:T], lpf_square_wave_75[0:T],label=\"out: LPF'd sine, coeff = 0.75\")\n",
    "ax.plot(t[0:T], lpf_square_wave_90[0:T],label=\"out: LPF'd sine, coeff = 0.90\")\n",
    "ax.plot(t[0:T], lpf_square_wave_95[0:T],label=\"out: LPF'd sine, coeff = 0.95\")\n",
    "\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just _saw_ what a complementary _**lowpass**_ filter does to a signal. Now let's _hear_ what it does to our heavily-clipped guitar recording.\n",
    "\n",
    "Before lowpass filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_hc05.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After lowpass filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('riff_hc05_lpf.wav',\n",
    "         lowpass_iir(riff_hc05_data,0.75),\n",
    "         44100)\n",
    "\n",
    "Audio(filename='riff_hc05_lpf.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sounds muffled, right? That means our lowpass filter is working!\n",
    "\n",
    "Now let's move on and implement a complementary _**highpass**_ filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complementary highpass filter\n",
    "The block diagram of a complementary highpass filter is\n",
    "<img src=\"https://raw.githubusercontent.com/dlynch7/reverse_engineer_guitar_fx/main/distortion/HPF.png\" alt=\"HPF.png\" width=\"500\"/>\n",
    "\n",
    "The equation for a complementary highpass filter is\n",
    "\\begin{equation}\n",
    "y[n]=(1-b) x[n] + b(x[n]-x[n-1])\n",
    "\\end{equation}\n",
    "\n",
    "Again, think of this as a weighted average between the current input and the previous output, and again consider two limits:\n",
    "* As $b\\rightarrow 0$, $y[n] \\rightarrow x[n]$, in which case the output is simply the input, and no filtering occurs; all input signal content is passed through.\n",
    "* As $b\\rightarrow 1$, $y[n] \\rightarrow x[n]-x[n-1]$, in which case the output is maximally highpass filtered, as it tracks the _difference_ between the current input and the previous input, thereby approximating the continuous-time derivative of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highpass_iir(sig_in,filt_coef):\n",
    "    if not type(sig_in) is np.ndarray:\n",
    "      raise TypeError('type(sig_in) must be numpy.ndarray')\n",
    "    if not (type(filt_coef) is float or type(filt_coef) is int):\n",
    "      raise TypeError('type(filt_coef) must be float or int')\n",
    "    if (filt_coef > 1 or filt_coef < 0):\n",
    "      raise ValueError('filt_coef must be between 0 and 1.')\n",
    "    \n",
    "    sig_out = np.zeros_like(sig_in)\n",
    "#     print(sig_out.shape)\n",
    "    \n",
    "    for n in range(1,sig_in.shape[0]): # notice that we're starting at \"1\" instead of \"0\"\n",
    "        sig_out[n] = (1-filt_coef)*sig_in[n] + filt_coef*(sig_in[n] - sig_in[n-1])\n",
    "    \n",
    "    return sig_out\n",
    "\n",
    "# To test our highpass filter, create a sinusoidal signal and then hard-clip it:\n",
    "samplerate = 44100; fs = 100\n",
    "t = np.linspace(0., 1, samplerate)\n",
    "amplitude = 1\n",
    "sine_data = amplitude * np.sin(2. * np.pi * fs * t)\n",
    "hard_clip_mu_10 = hard_clipper_makeup(sine_data,0.10) # this will look like a square wave: lots of harmonic content!\n",
    "\n",
    "# Now let's highpass-filter our quasi-square wave:\n",
    "hpf_square_wave_50 = highpass_iir(hard_clip_mu_10,0.5) # set the filter coefficient to 0.5\n",
    "hpf_square_wave_75 = highpass_iir(hard_clip_mu_10,0.75) # set the filter coefficient to 0.75\n",
    "hpf_square_wave_90 = highpass_iir(hard_clip_mu_10,0.90) # set the filter coefficient to 0.90\n",
    "hpf_square_wave_95 = highpass_iir(hard_clip_mu_10,0.95) # set the filter coefficient to 0.90\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(20, 10))\n",
    "T = 1000\n",
    "ax.plot(t[0:T], sine_data[0:T],label='pure sine')\n",
    "ax.plot(t[0:T], hard_clip_mu_10[0:T],label='in: hard-clipped sine, thresh = 0.10')\n",
    "ax.plot(t[0:T], hpf_square_wave_50[0:T],label=\"out: HPF'd sine, coeff = 0.5\")\n",
    "ax.plot(t[0:T], hpf_square_wave_75[0:T],label=\"out: HPF'd sine, coeff = 0.75\")\n",
    "ax.plot(t[0:T], hpf_square_wave_90[0:T],label=\"out: HPF'd sine, coeff = 0.90\")\n",
    "ax.plot(t[0:T], hpf_square_wave_95[0:T],label=\"out: HPF'd sine, coeff = 0.95\")\n",
    "\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's hear what it sounds like, again applied to our hard-clipped guitar signal. First, here's the un-filtered recording:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_hc05.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, the highpass-filtered version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('riff_hc05_hpf.wav',\n",
    "         highpass_iir(riff_hc05_data,0.90),\n",
    "         44100)\n",
    "Audio(filename='riff_hc05_hpf.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sounds tinnier, right? That means our complementary highpass filter is working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complementary bandpass filter\n",
    "We can simply cascade the lowpass and highpass filters:\n",
    "<img src=\"https://raw.githubusercontent.com/dlynch7/reverse_engineer_guitar_fx/main/distortion/BPF.png\" alt=\"BPF.png\" width=\"400\"/>\n",
    "Mathematically,\n",
    "\\begin{align}\n",
    "w[n]=(1-a)x[n] + a w[n-1],\\\\\n",
    "y[n]=(1-b)w[n] + b(w[n]-w[n-1]),\n",
    "\\end{align}\n",
    "\n",
    "Again, consider the limit cases:\n",
    "* As $a,b\\rightarrow 0$, $y[n] \\rightarrow x[n]$ (pass-through);\n",
    "* Hold $a=0$; as $b\\rightarrow 1$, $y[n] \\rightarrow x[n]-x[n-1]$ (highpass);\n",
    "* Hold $b=0$; as $a\\rightarrow 1$, $y[n] \\rightarrow y[n-1]$ (lowpass);\n",
    "* As $a,b\\rightarrow 1$; the cascaded filters work as a bandpass filter, letting mid-frequency content pass through while attenuating low-frequency and high-frequency content. If you let $a < b$, some frequency range of the input signal will be unattenuated.\n",
    "\n",
    "Now, let's implement this in a function. If we were writing a real-time audio application, we would have to write this in a way that works with streaming input and output, but instead, we'll write our function to post-process an existing signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_iir(sig_in,lpf_coef,hpf_coef):\n",
    "    # this function just calls other functions we wrote,\n",
    "    # and those functions check their inputs, so we don't need to do that here.\n",
    "    \n",
    "    # first, lowpass-filter the input signal\n",
    "    sig_med = lowpass_iir(sig_in,lpf_coef)\n",
    "    \n",
    "    # second, highpass-filter the lowpass-filtered signal\n",
    "    sig_out = highpass_iir(sig_med,hpf_coef)\n",
    "    \n",
    "    return sig_out\n",
    "\n",
    "# To test our bandpass filter, create a sinusoidal signal and then hard-clip it:\n",
    "samplerate = 44100; fs = 100\n",
    "t = np.linspace(0., 1, samplerate)\n",
    "amplitude = 1\n",
    "sine_data = amplitude * np.sin(2. * np.pi * fs * t)\n",
    "hard_clip_mu_10 = hard_clipper_makeup(sine_data,0.10) # this will look like a square wave: lots of harmonic content!\n",
    "\n",
    "# Now let's highpass-filter our quasi-square wave:\n",
    "bpf_square_wave_10_10 = bandpass_iir(hard_clip_mu_10,0.1,0.1) # LPF coefficient = HPF coefficient = 0.1\n",
    "bpf_square_wave_10_20 = bandpass_iir(hard_clip_mu_10,0.1,0.2) # LPF coef = 0.1, HPF coef = 0.2\n",
    "bpf_square_wave_20_50 = bandpass_iir(hard_clip_mu_10,0.2,0.5) # LPF coef = 0.2, HPF coef = 0.5\n",
    "bpf_square_wave_50_90 = bandpass_iir(hard_clip_mu_10,0.5,0.9) # LPF coef = 0.5, HPF coef = 0.9\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(20, 10))\n",
    "T = 1000\n",
    "ax.plot(t[0:T], sine_data[0:T],label='pure sine')\n",
    "ax.plot(t[0:T], hard_clip_mu_10[0:T],label='in: hard-clipped sine, thresh = 0.10')\n",
    "ax.plot(t[0:T], bpf_square_wave_10_10[0:T],label=\"out: BPF'd sine, coeffs = (0.1,0.1)\")\n",
    "ax.plot(t[0:T], bpf_square_wave_10_20[0:T],label=\"out: BPF'd sine, coeffs = (0.1,0.2)\")\n",
    "ax.plot(t[0:T], bpf_square_wave_20_50[0:T],label=\"out: BPF'd sine, coeffs = (0.2,0.5)\")\n",
    "ax.plot(t[0:T], bpf_square_wave_50_90[0:T],label=\"out: BPF'd sine, coeffs = (0.5,0.9)\")\n",
    "\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's test it out on our guitar recording. Here's the unfiltered recording:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_hc05.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's a bandpass-filtered version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('riff_hc05_bpf.wav',\n",
    "         bandpass_iir(riff_hc05_data,0.75,0.9),\n",
    "         44100)\n",
    "\n",
    "Audio(filename='riff_hc05_bpf.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, here's the lowpass-filtered version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_hc05_lpf.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also for comparison, here's the highpass-filtered version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_hc05_hpf.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascade # 1: bandpass filter, then clip\n",
    "Now let's start putting things together.\n",
    "1. First, we'll bandpass-filter the incoming signal;\n",
    "2. Then, we'll send the filtered signal through our clipping stage (with makeup gain).\n",
    "\n",
    "Remember why we're going this:\n",
    "* by filtering out some of the low-frequency content from the clean guitar signal, we can apply more distortion via clipping before the output starts to sound bad\n",
    "* there isn't much frequency content above a few kHz coming from the guitar, so we might as well filter out what little is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpf_and_clip(sig_in,lpf_coef,hpf_coef,clip_thresh):\n",
    "    # this function just calls the other functions we wrote,\n",
    "    # and they check their inputs, so we don't need to do that here.\n",
    "    \n",
    "    # First, bandpass-filter the input signal:\n",
    "    sig_med = bandpass_iir(sig_in,lpf_coef,hpf_coef)\n",
    "    \n",
    "    # Second, hard-clip the bandpass-filtered signal:\n",
    "    sig_out = hard_clipper_makeup(sig_med,clip_thresh)\n",
    "    \n",
    "    return sig_out\n",
    "\n",
    "# test it out on audio directly:\n",
    "lpf_coef = 0.75\n",
    "hpf_coef = 0.99\n",
    "clip_thresh = 0.001\n",
    "samplerate = 44100\n",
    "\n",
    "sf.write('riff_bpf_hc.wav',\n",
    "         bpf_and_clip(riff_clean_data,lpf_coef,hpf_coef,clip_thresh),\n",
    "         samplerate)\n",
    "\n",
    "Audio(filename='riff_bpf_hc.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, here's our target sound, for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_dist.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascade #2: BPF, then clip, then BPF\n",
    "Now it's getting pretty close, but our reverse-engineered signal chain still sounds harsh on the ears, and I think some additional filtering after the clipping stage will help with this.\n",
    "\n",
    "This is also what is done in the ProCo RAT, the Boss MT-2 Metal Zone, and many other distortion units.\n",
    "\n",
    "The overarching goal is to pack as much distortion into our effects as possible without it sounding \"crappy\", and smoothing out the clipper's output will help with that. Let's give it a shot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpf_clip_bpf(sig_in,lpf_coef1,hpf_coef1,clip_thresh,lpf_coef2,hpf_coef2):\n",
    "    # this function just calls the other functions we wrote,\n",
    "    # and they check their inputs, so we don't need to do that here.\n",
    "    \n",
    "    # First, bandpass-filter the input signal:\n",
    "    sig_1 = bandpass_iir(sig_in,lpf_coef,hpf_coef)\n",
    "    \n",
    "    # Second, hard-clip the bandpass-filtered signal:\n",
    "    sig_2 = hard_clipper_makeup(sig_1,clip_thresh)\n",
    "    \n",
    "    # Third, lowpass-filter the clipped signal:\n",
    "    sig_out = bandpass_iir(sig_2,lpf_coef2,hpf_coef2)\n",
    "    \n",
    "    return sig_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the clean guitar signal, which we're going to distort the heck out of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_clean.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the function we just wrote to process the clean signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpf_coef1 = 0.5\n",
    "hpf_coef1 = 0.999\n",
    "clip_thresh = 0.0001\n",
    "lpf_coef2 = 0.875\n",
    "hpf_coef2 = 0.6\n",
    "samplerate = 44100\n",
    "\n",
    "sf.write('riff_bpf_hc_bpf.wav',\n",
    "         bpf_clip_bpf(riff_clean_data,lpf_coef1,hpf_coef1,clip_thresh,lpf_coef2,hpf_coef2),\n",
    "         samplerate)\n",
    "\n",
    "Audio(filename='riff_bpf_hc_bpf.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, here's our target sound, for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='riff_dist.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFTs of the guitar signal at each stage in the effects chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://realpython.com/python-scipy-fft/\n",
    "\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "\n",
    "lpf_coef1 = 0.5\n",
    "hpf_coef1 = 0.999\n",
    "clip_thresh = 0.0001\n",
    "lpf_coef2 = 0.9 # 0.85\n",
    "hpf_coef2 = 0.7\n",
    "\n",
    "# Number of samples:\n",
    "samplerate = 44100\n",
    "N = samplerate # N is the number of samples, and (below) we're going to restrict ourselves to 1 second of data\n",
    "\n",
    "fmax = int(2e4)\n",
    "xf = [[],[],[],[]]\n",
    "yf = [[],[],[],[]]\n",
    "yf_db = [[],[],[],[]]\n",
    "\n",
    "# take the FFT of the clean guitar signal:\n",
    "yf[0] = rfft(riff_clean_data[0:N][:,0])\n",
    "yf_db[0] = 20 * np.log10(np.abs(yf[0] / yf[0][0]))\n",
    "xf[0] = rfftfreq(N, 1/samplerate)\n",
    "\n",
    "# FFT of bandpass-filtered guitar signal:\n",
    "bpf_data = bpf_clip_bpf(riff_clean_data,lpf_coef1,hpf_coef1,1,0,0)\n",
    "yf[1] = rfft(bpf_data[0:N][:,0])\n",
    "yf_db[1] = 20 * np.log10(np.abs(yf[1] / yf[0][0]))\n",
    "xf[1] = rfftfreq(N, 1/samplerate)\n",
    "\n",
    "# FFT of bandpass-filtered and hard-clipped guitar signal:\n",
    "bpf_hc_data = bpf_clip_bpf(riff_clean_data,lpf_coef1,hpf_coef1,clip_thresh,0,0)\n",
    "yf[2] = rfft(bpf_hc_data[0:N][:,0])\n",
    "yf_db[2] = 20 * np.log10(np.abs(yf[2] / yf[0][0]))\n",
    "xf[2] = rfftfreq(N, 1/samplerate)\n",
    "\n",
    "# FFT of bandpass-filtered, hard-clipped, then re-bandpass-filtered guitar signal:\n",
    "bpf_hc_bpf_data = bpf_clip_bpf(riff_clean_data,lpf_coef1,hpf_coef1,clip_thresh,lpf_coef2,hpf_coef2)\n",
    "yf[3] = rfft(bpf_hc_bpf_data[0:N][:,0])\n",
    "yf_db[3] = 20 * np.log10(np.abs(yf[3] / yf[0][0]))\n",
    "xf[3] = rfftfreq(N, 1/samplerate)\n",
    "\n",
    "fig, axs = plt.subplots(2,2,figsize=(20,20))\n",
    "axs[0,0].plot(xf[0][0:fmax], yf_db[0][0:fmax])\n",
    "axs[0,0].set_xlabel('Frequency [Hz]')\n",
    "axs[0,0].set_xscale('log')\n",
    "axs[0,0].set_ylabel('Amplitude [dB]')\n",
    "axs[0,0].set_title('FFT, clean signal')\n",
    "\n",
    "axs[0,1].plot(xf[1][0:fmax], yf_db[1][0:fmax])\n",
    "axs[0,1].set_xlabel('Frequency [Hz]')\n",
    "axs[0,1].set_xscale('log')\n",
    "axs[0,1].set_ylabel('Amplitude [dB]')\n",
    "axs[0,1].set_title(\"FFT, BPF'd signal\")\n",
    "\n",
    "axs[1,0].plot(xf[2][0:fmax], yf_db[2][0:fmax])\n",
    "axs[1,0].set_xlabel('Frequency [Hz]')\n",
    "axs[1,0].set_xscale('log')\n",
    "axs[1,0].set_ylabel('Amplitude [dB]')\n",
    "axs[1,0].set_title(\"FFT, BPF'd & hard-clipped signal\")\n",
    "\n",
    "axs[1,1].plot(xf[3][0:fmax], yf_db[3][0:fmax])\n",
    "axs[1,1].set_xlabel('Frequency [Hz]')\n",
    "axs[1,1].set_xscale('log')\n",
    "axs[1,1].set_ylabel('Amplitude [dB]')\n",
    "axs[1,1].set_title(\"FFT, BPF'd, hard-clipped, re-BPF'd signal\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We managed to get a decent approximation of the distorted guitar recording, using a cascade of pretty simple effects units:\n",
    "* bandpass filter (itself implemented as a cascade: a lowpass complementary filter followed by a highpass complementary filter)\n",
    "* hard-clipping followed by makeup gain\n",
    "* another bandpass filter to smooth the sonic rough edges introduced by hard-clipping\n",
    "\n",
    "Still, our reverse-engineered effects chain doesn't quite sound like the original recording, and there are a number of things that could be done to get closer. Three extensions that stand out are\n",
    "* apply some \"compression\" (aka dynamic gain control) to the clean input before filtering it, clipping it, etc. This will provide a more uniform signal to the effects later in the signal chain, and that could be advantageous;\n",
    "* replace the hard-clipping effect with a soft-clipping effect: instead of simply saturating the input signal, a smooth function like a logistic curve or the arctangent could be used to achieve the desired distortion with less of a \"bitcrushed\" sound;\n",
    "* put more effort into filter design, starting with replacing the complementary filters with finite-impulse-response filters, which introduce fewer audio artifacts and whose frequency-domain properties can be designed using SciPy tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reverse Engineering Guitar FX.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
